import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
import ast
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader, TensorDataset
import matplotlib.pyplot as plt  # Add this import at the top of your file

# =========================
# Step 1: Define the Neural Network
# =========================
hidden_size = 1536  
num_epochs = 300
learning_rate = 0.0005
batch_size = 512
factor = 0.8
class RobotNN(nn.Module):
    def __init__(self, input_size, hidden_size=hidden_size, output_size=4):
        super(RobotNN, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.dropout1 = nn.Dropout(p=0.3)
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.dropout2 = nn.Dropout(p=0.3)
        self.fc3 = nn.Linear(hidden_size, hidden_size)
        self.dropout3 = nn.Dropout(p=0.3)
        self.fc4 = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout1(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout2(x)
        x = self.fc3(x)
        x = self.relu(x)
        x = self.dropout3(x)
        x = self.fc4(x)
        return x


# =========================
# Step 2: Load Training Data from CSV
# =========================
def load_training_data(csv_file, max_length=360):
    """
    Loads Lidar scan data and actions from a CSV file.
    The CSV is expected to have:
    - First column: JSON-like string of Lidar scan data (angle + distance pairs)
    - Last column: Action (0=Forward, 1=Left, 2=Right, 3=Stop)
    """
    df = pd.read_csv(csv_file, header=None)  # Load CSV without assuming headers

    # Parse the JSON-like strings in the first column
    lidar_data = df.iloc[:, 0].apply(ast.literal_eval)  # Convert strings to Python lists

    # Create a 360-item array for each Lidar scan
    def process_scan(scan):
        distances = [0] * max_length  # Initialize array with zeros
        for angle, distance in scan:
            rounded_angle = round(angle)  # Round angle to the nearest integer
            if 0 <= rounded_angle < max_length:  # Ensure angle is within bounds
                distances[rounded_angle] = distance
        return distances

    X = lidar_data.apply(process_scan).tolist()

    # Normalize distances (scale between -1 and 1)
    X = np.array(X)
    X = (X / np.max(X)) * 2 - 1

    # Extract the action labels (last column)
    y = df.iloc[:, 1].values

    # Split data into training and validation sets
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

    return torch.tensor(X_train, dtype=torch.float32), torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long), torch.tensor(y_val, dtype=torch.long)


# =========================
# Step 3: Train the AI Model
# =========================
def train_model(csv_file, num_epochs=num_epochs, learning_rate=learning_rate, batch_size=batch_size):
    # Load data
    X_train, X_val, y_train, y_val = load_training_data(csv_file)
    input_size = X_train.shape[1]  # Dynamically determine input size

    # Create DataLoaders
    train_dataset = TensorDataset(X_train, y_train)
    val_dataset = TensorDataset(X_val, y_val)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, pin_memory=True)

    # Initialize model
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = RobotNN(input_size=input_size).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)

    # Add a learning rate scheduler
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=factor, patience=10)

    # Early stopping parameters
    best_val_loss = float('inf')
    best_epoch = -1
    best_train_loss = None
    best_lr = None

    # Lists to store loss values for plotting
    train_losses = []
    val_losses = []

    # Training loop
    for epoch in range(num_epochs):
        model.train()
        epoch_train_loss = 0
        for X_batch, y_batch in train_loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)
            optimizer.zero_grad()
            outputs = model(X_batch)
            loss = criterion(outputs, y_batch)
            loss.backward()
            optimizer.step()
            epoch_train_loss += loss.item()

        epoch_train_loss /= len(train_loader)  # Average training loss
        train_losses.append(epoch_train_loss)

        # Evaluate on validation set
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for X_batch, y_batch in val_loader:
                X_batch, y_batch = X_batch.to(device), y_batch.to(device)
                val_outputs = model(X_batch)
                val_loss += criterion(val_outputs, y_batch).item()
        val_loss /= len(val_loader)  # Average validation loss
        val_losses.append(val_loss)

        # Step the scheduler
        scheduler.step(val_loss)

        # Print learning rate and losses every 10 epochs
        current_lr = scheduler.optimizer.param_groups[0]['lr']  # Get current learning rate
        
        print(f'Epoch [{epoch}/{num_epochs}], Loss: {epoch_train_loss:.4f}, Val Loss: {val_loss:.4f}, LR: {current_lr:.6f}')

        # Update best epoch info
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_epoch = epoch
            best_train_loss = epoch_train_loss
            best_lr = current_lr
            torch.save(model.state_dict(), "best_model.pth")  # Save the best model

    print("Training complete!")

    # Print the best epoch info
    print(f"Best Epoch: {best_epoch}")
    print(f"Epoch [{best_epoch}/300] Loss: {best_train_loss:.4f}, Val Loss: {best_val_loss:.4f}, LR: {best_lr:.6f}")

    # Save the trained model
    torch.save(model.state_dict(), "robot_model.pth")
    print("Model saved successfully!")

    # Plot training and validation loss
    plt.figure(figsize=(10, 6))
    plt.plot(range(num_epochs), train_losses, label='Training Loss')
    plt.plot(range(num_epochs), val_losses, label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss')
    plt.legend()
    plt.grid()
    plt.show()


# =========================
# Step 4: Run Training
# =========================
csv_filename = "lidar_training_data.csv"  # Change this to your CSV file name
train_model(csv_filename)
